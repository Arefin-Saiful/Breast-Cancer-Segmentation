{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11038340,"sourceType":"datasetVersion","datasetId":6875454}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Step 1: Imports & Paths","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom skimage import exposure\nfrom skimage.filters import threshold_local\nfrom skimage.morphology import closing, remove_small_objects, remove_small_holes, disk\nfrom scipy import ndimage as ndi\nfrom skimage.feature import peak_local_max\nfrom skimage.segmentation import watershed\n\n# ── UPDATE THESE PATHS ─────────────────────────────────────────────────────────\ntrain_dir   = '/kaggle/input/her2-based-breast-cancer-diagnosis/her2_Train/Train'\nmask_dir    = '/kaggle/working/masks_train'\noverlay_dir = '/kaggle/working/overlays_train'\n# If you have ground-truth masks for evaluation:\n\n# ───────────────────────────────────────────────────────────────────────────────\n\nos.makedirs(mask_dir,    exist_ok=True)\nos.makedirs(overlay_dir, exist_ok=True)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:07:22.637925Z","iopub.execute_input":"2025-05-08T16:07:22.638173Z","iopub.status.idle":"2025-05-08T16:07:23.596645Z","shell.execute_reply.started":"2025-05-08T16:07:22.638153Z","shell.execute_reply":"2025-05-08T16:07:23.595862Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"**Step 2: Preprocessing Function**","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom skimage import exposure\nfrom skimage.morphology import opening, disk\n\ndef preprocess_image(img, resize_dim=(512,512)):\n    # 1) Resize\n    img_r = cv2.resize(img, resize_dim)\n    \n    # 2) Denoise with Gaussian blur\n    blur  = cv2.GaussianBlur(img_r, (5, 5), 0)\n    \n    # 3) Convert to LAB and apply CLAHE on L-channel\n    lab   = cv2.cvtColor(blur, cv2.COLOR_BGR2LAB)\n    l, a, b = cv2.split(lab)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    l_eq  = clahe.apply(l)\n    lab_eq = cv2.merge((l_eq, a, b))\n    img_eq = cv2.cvtColor(lab_eq, cv2.COLOR_LAB2BGR)\n    \n    # 4) Convert to grayscale\n    gray = cv2.cvtColor(img_eq, cv2.COLOR_BGR2GRAY)\n    \n    # 5) Background subtraction via morphological opening\n    bg = opening(gray, disk(50))                  # estimate background\n    fg = gray.astype(np.int32) - bg.astype(np.int32)\n    fg = np.clip(fg, 0, 255).astype(np.uint8)\n    \n    # 6) Histogram equalization + percentile stretch\n    eq = exposure.equalize_hist(fg)\n    p2, p98      = np.percentile(eq, (2, 98))\n    stretched   = exposure.rescale_intensity(eq, in_range=(p2, p98))\n    \n    # 7) Inversion so nuclei are bright\n    return 1.0 - stretched\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:07:23.597586Z","iopub.execute_input":"2025-05-08T16:07:23.597914Z","iopub.status.idle":"2025-05-08T16:07:23.605913Z","shell.execute_reply.started":"2025-05-08T16:07:23.597892Z","shell.execute_reply":"2025-05-08T16:07:23.605175Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"**Step 3: Adaptive Thresholding**","metadata":{}},{"cell_type":"code","source":"# Step 3: Adaptive Thresholding (final tweak)\nfrom skimage.filters import threshold_local\n\n# Map magnification levels to odd block sizes\nmag_to_block = {20: 21, 40: 43, 80: 85}\n\ndef adaptive_thresholding(pre_img, magnification=40, offset=0.02):\n    \"\"\"\n    Local threshold: nuclei > local mean + 0.02.\n    A slightly stricter offset helps suppress residual background.\n    \"\"\"\n    # Choose block size based on magnification\n    b = mag_to_block.get(magnification, 43)\n    if b % 2 == 0:\n        b += 1\n    # Compute local threshold and binarize\n    thr = threshold_local(pre_img, block_size=b, offset=offset)\n    return pre_img > thr\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:07:23.606557Z","iopub.execute_input":"2025-05-08T16:07:23.606777Z","iopub.status.idle":"2025-05-08T16:07:23.634071Z","shell.execute_reply.started":"2025-05-08T16:07:23.606761Z","shell.execute_reply":"2025-05-08T16:07:23.633427Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"**Step 4: Morphological Filtering**","metadata":{}},{"cell_type":"code","source":"# Step 4: Morphological Filtering (noise-removal pass, final tweak)\nfrom skimage.morphology import opening, closing, remove_small_objects, remove_small_holes, disk\n\ndef morphological_filtering(binary_mask,\n                            min_size=200,    # drop any object <200 px\n                            hole_area=100,   \n                            open_size=1,     # minimal opening to remove speckles\n                            close_size=2):   # small closing to bridge gaps\n    \"\"\"\n    1) Opening with disk(open_size) to remove tiny noise speckles.\n    2) Closing with disk(close_size) to join touching nuclei.\n    3) Remove objects smaller than min_size.\n    4) Fill holes smaller than hole_area.\n    \"\"\"\n    se_open  = disk(open_size)\n    se_close = disk(close_size)\n\n    opened  = opening(binary_mask, se_open)\n    closed  = closing(opened,   se_close)\n    cleaned = remove_small_objects(closed,   min_size=min_size)\n    filled  = remove_small_holes(cleaned,    area_threshold=hole_area)\n    return filled\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:07:23.635795Z","iopub.execute_input":"2025-05-08T16:07:23.636160Z","iopub.status.idle":"2025-05-08T16:07:23.650332Z","shell.execute_reply.started":"2025-05-08T16:07:23.636138Z","shell.execute_reply":"2025-05-08T16:07:23.649400Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"**Step 5: Watershed Separation**","metadata":{}},{"cell_type":"code","source":"# Step 5: Watershed Separation (final tweak)\nfrom scipy import ndimage as ndi\nfrom skimage.feature import peak_local_max\nfrom skimage.segmentation import watershed\nimport numpy as np\n\ndef separate_nuclei_watershed(clean_mask, min_distance=3):\n    \"\"\"\n    1) Compute distance transform.\n    2) Find local maxima as markers with min_distance=3.\n    3) Build marker image from those peaks.\n    4) Run watershed on -distance to split touching nuclei.\n    \"\"\"\n    # 1) Distance transform\n    dist = ndi.distance_transform_edt(clean_mask)\n\n    # 2) Peak detection with tighter spacing\n    coords = peak_local_max(dist, labels=clean_mask, min_distance=min_distance)\n\n    # 3) Build marker image from detected peaks\n    markers = np.zeros(clean_mask.shape, dtype=int)\n    for idx, (r, c) in enumerate(coords, start=1):\n        markers[r, c] = idx\n\n    # 4) Apply watershed segmentation\n    labels = watershed(-dist, markers, mask=clean_mask)\n    return labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:07:23.651006Z","iopub.execute_input":"2025-05-08T16:07:23.651264Z","iopub.status.idle":"2025-05-08T16:07:23.676962Z","shell.execute_reply.started":"2025-05-08T16:07:23.651240Z","shell.execute_reply":"2025-05-08T16:07:23.676405Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"**Step 6: Post-Filtering**","metadata":{}},{"cell_type":"code","source":"# Step 6: Post‐Filtering with Area Bounds (final tweak)\nimport numpy as np\n\ndef filter_labels(label_mask,\n                  min_area=100,   # keep regions ≥ 100 px\n                  max_area=1000,  # drop regions > 1000 px (tighter bound)\n                  max_ecc=0.95):\n    \"\"\"\n    Iterate each connected component in `label_mask`:\n      - Compute area and eccentricity.\n      - Keep only if 100 ≤ area ≤ 1000 AND eccentricity ≤ 0.95.\n    \"\"\"\n    out = np.zeros_like(label_mask, dtype=np.uint8)\n    for lbl in np.unique(label_mask):\n        if lbl == 0:\n            continue\n        region = (label_mask == lbl)\n        area   = region.sum()\n        # Skip regions outside area bounds\n        if not (min_area <= area <= max_area):\n            continue\n\n        # Compute eccentricity from covariance of pixel coords\n        coords = np.column_stack(np.nonzero(region))\n        cov    = np.cov(coords, rowvar=False)\n        eigs   = np.linalg.eigvals(cov)\n        ecc    = np.sqrt(1 - min(eigs)/max(eigs)) if max(eigs) > 0 else 0\n\n        if ecc <= max_ecc:\n            out[region] = 1\n\n    return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:07:23.677493Z","iopub.execute_input":"2025-05-08T16:07:23.677704Z","iopub.status.idle":"2025-05-08T16:07:23.693429Z","shell.execute_reply.started":"2025-05-08T16:07:23.677685Z","shell.execute_reply":"2025-05-08T16:07:23.692728Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"**Step 7: Single-Image Segmentation Wrapper**","metadata":{}},{"cell_type":"code","source":"# Step 7: Updated Single-Image Segmentation Wrapper (final tuned version)\nimport cv2\n\ndef segment_nuclei(img_path,\n                   mask_out_path,\n                   overlay_out_path,\n                   magnification=40):\n    \"\"\"\n    1) Read image and resize to 512×512\n    2) Preprocess with blur, CLAHE, and background subtraction\n    3) Adaptive thresholding (offset=0.02)\n    4) Morphological filtering (open_size=1, close_size=2, min_size=200)\n    5) Watershed (min_distance=3)\n    6) Post-filtering (100 ≤ area ≤ 1000, ecc ≤ 0.95)\n    7) Save mask and overlay at 512×512\n    8) Optional: upscale overlay to original resolution\n    \"\"\"\n    # 1) Load & resize\n    orig    = cv2.imread(img_path)\n    seg_img = cv2.resize(orig, (512, 512))\n\n    # 2) Preprocess\n    pre = preprocess_image(seg_img)\n\n    # 3) Threshold\n    thr = adaptive_thresholding(pre, magnification, offset=0.02)\n\n    # 4) Morphology\n    mor = morphological_filtering(\n        thr,\n        min_size=200,\n        hole_area=100,\n        open_size=1,\n        close_size=2\n    )\n\n    # 5) Watershed\n    lbl = separate_nuclei_watershed(mor, min_distance=3)\n\n    # 6) Post-filter\n    final_mask = filter_labels(\n        lbl,\n        min_area=100,\n        max_area=1000,\n        max_ecc=0.95\n    )\n\n    # 7) Save mask & overlay (512×512)\n    mask_uint8 = (final_mask * 255).astype(np.uint8)\n    cv2.imwrite(mask_out_path, mask_uint8)\n    overlay = seg_img.copy()\n    overlay[mask_uint8 == 255] = [255, 0, 0]\n    blend   = cv2.addWeighted(seg_img, 0.7, overlay, 0.3, 0)\n    cv2.imwrite(overlay_out_path, blend)\n\n    # 8) Optional: upscale overlay to original resolution\n    mask_full    = cv2.resize(mask_uint8,\n                              (orig.shape[1], orig.shape[0]),\n                              interpolation=cv2.INTER_NEAREST)\n    overlay_full = orig.copy()\n    overlay_full[mask_full == 255] = [255, 0, 0]\n    blend_full   = cv2.addWeighted(orig, 0.7, overlay_full, 0.3, 0)\n    orig_overlay = overlay_out_path.replace('.png', '_orig_overlay.png')\n    cv2.imwrite(orig_overlay, blend_full)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:07:23.694177Z","iopub.execute_input":"2025-05-08T16:07:23.694402Z","iopub.status.idle":"2025-05-08T16:07:23.714753Z","shell.execute_reply.started":"2025-05-08T16:07:23.694382Z","shell.execute_reply":"2025-05-08T16:07:23.714059Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"**Step 8: Batch-Process All Classes**","metadata":{}},{"cell_type":"code","source":"# Step 8: Updated Batch-Process All Classes Cell\n\nimport os\nimport glob\n\n# Ensure train_dir, mask_dir, and overlay_dir are defined above this cell\n\nclasses = sorted(\n    d for d in os.listdir(train_dir)\n    if os.path.isdir(os.path.join(train_dir, d))\n)\n\nfor cls in classes:\n    in_dir = os.path.join(train_dir, cls)\n    out_m  = os.path.join(mask_dir,  cls)\n    out_o  = os.path.join(overlay_dir, cls)\n    os.makedirs(out_m, exist_ok=True)\n    os.makedirs(out_o, exist_ok=True)\n\n    for img_fp in glob.glob(os.path.join(in_dir, '*.*')):\n        fname     = os.path.splitext(os.path.basename(img_fp))[0]\n        mask_path = os.path.join(out_m, f\"{fname}_mask.png\")\n        overlay_path = os.path.join(out_o, f\"{fname}_overlay.png\")\n        segment_nuclei(img_fp, mask_path, overlay_path)\n\nprint(\"✅ Batch segmentation complete.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:07:23.715595Z","iopub.execute_input":"2025-05-08T16:07:23.715937Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = '/kaggle/input/her2-based-breast-cancer-diagnosis/her2_Train/Train'\nmask_dir  = '/kaggle/working/masks_train'\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Step 9: (Optional) Evaluation Metrics**","metadata":{}},{"cell_type":"markdown","source":"**Step 10: Before-&-After Visuals per Class**","metadata":{}},{"cell_type":"code","source":"def show_before_after(classes, n=1, resize_dim=(512,512)):\n    for cls in classes:\n        samples = glob.glob(os.path.join(train_dir, cls, '*.*'))[:n]\n        fig, axs = plt.subplots(n, 2, figsize=(8, 4*n))\n        \n        for i, fp in enumerate(samples):\n            base = os.path.splitext(os.path.basename(fp))[0]\n            orig = cv2.imread(fp)\n            \n            # *** Resize original to match the mask size ***\n            seg_img = cv2.resize(orig, resize_dim)\n            \n            # Load the predicted mask (512×512)\n            mask_path = os.path.join(mask_dir, cls, f\"{base}_mask.png\")\n            pred = cv2.imread(mask_path, 0) > 0\n            \n            # Overlay the mask onto the resized image\n            overlay = seg_img.copy()\n            overlay[pred] = [255, 0, 0]\n            blend = cv2.addWeighted(seg_img, 0.7, overlay, 0.3, 0)\n            \n            # Select the correct axes\n            if n > 1:\n                ax1, ax2 = axs[i]\n            else:\n                ax1, ax2 = axs\n            \n            # Show resized original and segmentation\n            ax1.imshow(cv2.cvtColor(seg_img, cv2.COLOR_BGR2RGB))\n            ax1.set_title(f'{cls} Original (resized)')\n            ax1.axis('off')\n            \n            ax2.imshow(cv2.cvtColor(blend, cv2.COLOR_BGR2RGB))\n            ax2.set_title(f'{cls} Segmented (resized)')\n            ax2.axis('off')\n        \n        plt.tight_layout()\n        plt.show()\n\n# Then call it:\nclasses = sorted(d for d in os.listdir(train_dir)\n                 if os.path.isdir(os.path.join(train_dir, d)))\nshow_before_after(classes, n=2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom skimage.measure import label, regionprops\n\n# ── UPDATE PATH ────────────────────────────────────────────────────────────────\nmask_dir = '/kaggle/working/masks_train'\n# ────────────────────────────────────────────────────────────────────────────────\n\nclasses = sorted(d for d in os.listdir(mask_dir)\n                 if os.path.isdir(os.path.join(mask_dir, d)))\n\nrecords = []\nfor cls in classes:\n    for mask_fp in glob.glob(os.path.join(mask_dir, cls, '*_mask.png')):\n        name      = os.path.splitext(os.path.basename(mask_fp))[0].replace('_mask','')\n        mask      = cv2.imread(mask_fp, 0) > 0\n        # Label connected components\n        labeled   = label(mask)\n        props     = regionprops(labeled)\n        areas     = [p.area for p in props]\n        num_nuclei     = len(areas)\n        mean_area      = float(np.mean(areas)) if areas else 0\n        std_area       = float(np.std(areas))  if areas else 0\n        fg_ratio       = mask.sum() / mask.size\n\n        records.append({\n            'class': cls,\n            'image': name,\n            'num_nuclei': num_nuclei,\n            'mean_area': mean_area,\n            'std_area': std_area,\n            'fg_pixel_ratio': fg_ratio\n        })\n\ndf = pd.DataFrame(records)\n# Show per-class averages\nsummary = df.groupby('class').agg({\n    'num_nuclei':    'mean',\n    'mean_area':     'mean',\n    'std_area':      'mean',\n    'fg_pixel_ratio':'mean'\n}).rename(columns={\n    'num_nuclei':'avg_nuclei_count',\n    'mean_area':'avg_nucleus_area',\n    'std_area':'avg_area_std',\n    'fg_pixel_ratio':'avg_fg_ratio'\n})\nprint(summary)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}